#!/bin/bash

#SBATCH --partition=gpu_shared_course
#SBATCH --gres=gpu:1
#SBATCH --job-name=Transparency
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=3
#SBATCH --time=24:00:00
#SBATCH --mem=32000M
#SBATCH --output=./experiments/SLURM_%A.out

module purge
module load 2019
module load Python/3.7.5-foss-2019b
module load CUDA/10.1.243
module load cuDNN/7.6.5.32-CUDA-10.1.243
module load NCCL/2.5.6-CUDA-10.1.243
module load Anaconda3/2018.12

# Your job starts in the directory where you call sbatch
cd $HOME/Transparency
export PYTHONPATH="${PYTHONPATH}:$HOME"

# Activate your environment
source activate FACT2021

# Run your code
# srun python -u train_and_run_experiments_bc.py --dataset imdb --data_dir . --output_dir ./experiments --encoder vanilla_lstm --skip_rationale --run_lime --run_lime_additional
# srun python -u train_and_run_experiments_bc.py --dataset yelp --data_dir . --output_dir ./experiments --encoder ortho_lstm --skip_rationale --run_lime --run_lime_additional
# srun python -u train_and_run_experiments_bc.py --dataset yelp --data_dir . --output_dir ./experiments --encoder diversity_lstm --diversity 0.5 --run_lime --run_lime_additional

# srun python -u train_and_run_experiments_qa.py --dataset babi_3 --data_dir . --output_dir ./experiments --encoder vanilla_lstm
# srun python -u train_and_run_experiments_qa.py --dataset babi_1 --data_dir . --output_dir ./experiments --encoder ortho_lstm
# srun python -u train_and_run_experiments_qa.py --dataset snli --data_dir . --output_dir ./experiments --encoder diversity_lstm --diversity 0.5
